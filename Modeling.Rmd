---
title: "Modeling"
author: "aaron till"
date: "5/29/2018"
output: html_document
---
```{r}
#library(randomForest)
#library(caret)
library(glmnet)

```


```{r creating 50% random split for training/testing}

set.seed(1234)

train_indices <- sample(1:nrow(main_data), size = 330212, replace = FALSE) #half
train_data <- slice(main_data, train_indices) 
test_data  <- slice(main_data, -train_indices)


```

```{r missclassification function}

get_misclass <- function(model) {
  y <- predict(model, newdata = test, type = "response")
  test <- test %>%
    mutate(p_hat = y, pred_MME = p_hat > .5)
  table(test$MME, test$pred_MME)
  confusion_mat <- test %>%
    group_by(MME, pred_MME) %>%
    tally()
  false_pos <- confusion_mat[2, 3]
  false_neg <- confusion_mat[3, 3]
  total_obs <- nrow(test)
  misclassification <- (false_pos + false_neg)/total_obs
  misclassification


}
```




# Lasso Regression

```{r source - http://www.sthda.com/english/articles/36-classification-methods-essentials/149-penalized-logistic-regression-essentials-in-r-ridge-lasso-and-elastic-net/}

x <- model.matrix(MME ~ Year + Mean_Surf_Temp + Max_Surf_Temp + Mean_Surf_Zscore + Max_Surf_Zscore + layer_dif + Spring + Ice_Duration + Schmidt + Variance_After_Ice_30 + Cumulative_Above_0 + V2, train_data) 


y <- ifelse(train_data$MME == 1, 1, 0)

```



```{r observing lambdas and making final lasso regression model}
set.seed(1234)


lasso_regression_lambdas <- cv.glmnet(x, y, family = "binomial", alpha = 1) # alpha = 0 ridge, 1 for lasso, between 0 and 1 for elastic 

lasso_regression_model <- glmnet(x, y, family = "binomial", alpha = 1, lambda = lasso_regression_lambdas$lambda.1se) # alpha = 0 ridge, 1 for lasso, between 0 and 1 for elastic 
#use lambda.1se instead of lambda.min for simpler but less accurate model

#coef(lasso_regression_model)

```



```{r}

lasso_regression_test <- model.matrix(MME ~ Year + Mean_Surf_Temp + Max_Surf_Temp + Mean_Surf_Zscore + Max_Surf_Zscore + layer_dif + Spring + Ice_Duration + Schmidt + Variance_After_Ice_30 + Cumulative_Above_0 + V2, test_data)



probabilities <- lasso_regression_model %>% predict(newx = lasso_regression_test)
predicted_classes <- ifelse(probabilities > 0.5, "pos", "neg")
# Model accuracy 
observed_classes <- test_data$MME
mean(predicted_classes == observed_classes)



```


Main question: Why do lambda.min and lambda.1se both give me a 0 when computing effectiveness....what does this mean?  Is this bad or good?
 
 
# Lasso Just Summerkill

```{r source - }

x_summer <- model.matrix(Summerkill ~ Year + Mean_Surf_Temp + Max_Surf_Temp + Mean_Surf_Zscore + Max_Surf_Zscore + layer_dif + Spring + Schmidt + Variance_After_Ice_30 + Cumulative_Above_0 + V2, train_data) 


y_summer <- ifelse(train_data$Summerkill == 1, 1, 0)

```



```{r observing lambdas and making final lasso regression model}
set.seed(1234)


lasso_regression_lambda_summer <- cv.glmnet(x_summer, y_summer, family = "binomial", alpha = 1) # alpha = 0 ridge, 1 for lasso, between 0 and 1 for elastic 

lasso_regression_model_summer <- glmnet(x_summer, y_summer, family = "binomial", alpha = 1, lambda = lasso_regression_lambda_summer$lambda.1se) # alpha = 0 ridge, 1 for lasso, between 0 and 1 for elastic 
#use lambda.1se instead of lambda.min for simpler but less accurate model

coef(lasso_regression_model_summer)

```


 
# Normal Logistic Regression 



```{r creating reg_predictions and quartiles}
set.seed(1234)

regression_model <- glm(MME ~ Mean_Surf_Temp + layer_dif, family = 'binomial', data=main_data) # data sample for predictions

reg_predictions <- na.omit(future_data) # NEED TO MAKE STILL
reg_predictions$Prob <- predict(regression_model, na.omit(future_data), type = 'response')
#reg_predictions$MME <- ifelse(reg_predictions$Prob > 0.5, 1, 0) - WILL NEVER APPLY
reg_predictions$quantile <- quantile(reg_predictions$Prob,probs = c(min(reg_predictions$Prob), max(reg_predictions$Prob)), na.rm = TRUE)

```

```{r forecasting}
set.seed(1234)

a <- reg_predictions$Prob
simulation_log_regress <- rbinom(length(a), 1, prob = a)

reg_predictions$MME_forecast <- simulation_log_regress

```

```{r looking at trend of predictions}

change_MME_freq_future <- glm(MME_forecast ~ Year, family = 'binomial', data=reg_predictions)


summary(change_MME_freq_future) 

```



