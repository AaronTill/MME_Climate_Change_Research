---
title: "Modeling"
author: "aaron till"
date: "5/29/2018"
output: html_document
---
```{r}

library(caret)
library(glmnet)

```


```{r creating 50% random split for training/testing}

set.seed(1234)

train_indices <- sample(1:nrow(main_data), size = 330212, replace = FALSE) #half
train_data <- slice(main_data, train_indices) 
test_data  <- slice(main_data, -train_indices)





```



```{r http://www.sthda.com/english/articles/36-classification-methods-essentials/149-penalized-logistic-regression-essentials-in-r-ridge-lasso-and-elastic-net/}

x <- model.matrix(MME ~ Year + Mean_Surf_Temp + Max_Surf_Temp + Mean_Surf_Zscore + Max_Surf_Zscore + layer_dif + Spring + Ice_Duration + Schmidt + Variance_After_Ice_30 + Cumulative_Above_0 + V2, train_data) 

y <- ifelse(train_data$MME == 1, 1, 0)

```

```{r observing lambdas and making final lasso regression model}
set.seed(1234)


lasso_regression_lambdas <- cv.glmnet(x, y, family = "binomial", alpha = 1) # alpha = 0 ridge, 1 for lasso, between 0 and 1 for elastic 

lasso_regression_model <- glmnet(x, y, family = "binomial", alpha = 1, lambda = lasso_regression_lambdas$lambda.1se) # alpha = 0 ridge, 1 for lasso, between 0 and 1 for elastic 
#use lambda.1se instead of lambda.min for simpler but less accurate model

#coef(lasso_regression_model)

```



```{r}

lasso_regression_test <- model.matrix(MME ~ Year + Mean_Surf_Temp + Max_Surf_Temp + Mean_Surf_Zscore + Max_Surf_Zscore + layer_dif + Spring + Ice_Duration + Schmidt + Variance_After_Ice_30 + Cumulative_Above_0 + V2, test_data)



probabilities <- lasso_regression_model %>% predict(newx = lasso_regression_test)
predicted_classes <- ifelse(probabilities > 0.5, "pos", "neg")
# Model accuracy
observed_classes <- test_data$MME
mean(predicted_classes == observed_classes)



```


Main question: Why do lambda.min and lambda.1se both give me a 0 when computing effectiveness....what does this mean?  Is this bad or good?
 